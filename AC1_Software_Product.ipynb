{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atritiack/exemplo/blob/main/AC1_Software_Product.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0PwlVawUlYk"
      },
      "source": [
        "### **Atividade Contínua 01 - Software Product**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1: Importação de bibliotecas"
      ],
      "metadata": {
        "id": "5y3z-B4i6WkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Conversão de dados categóricos em numéricos:\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
        "\n",
        "# Normalização dos dados\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "\n",
        "# Separação em dados de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
      ],
      "metadata": {
        "id": "eXftjh2BfSm_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B4KH9_YVrmQ"
      },
      "source": [
        "# Parte 2: Preparação dos dados\n",
        "\n",
        "O conjunto de dados modificado \"census.csv\" consiste em aproximadamente 32.000 registros de dados, com cada registro de dados tendo 13 características.\n",
        "\n",
        "https://archive.ics.uci.edu/dataset/20/census+income\n",
        "\n",
        "Este conjunto de dados é uma versão modificada do conjunto de dados publicado no artigo \"*Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid*\", de Ron Kohavi.\n",
        "\n",
        "Artigo:\n",
        "\n",
        "https://aaai.org/papers/033-scaling-up-the-accuracy-of-naive-bayes-classifiers-a-decision-tree-hybrid/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsluTWi5V_FP"
      },
      "outputs": [],
      "source": [
        "# Criando um dataframe a partir do dados do arquivo\n",
        "df = pd.read_csv('/content/census.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleção de atributos (Dados de entrada)\n",
        "# Com o método .iloc selecionamos (por índice) todas as linhas,\n",
        "# e as colunas de 1 a 13 (o segundo parâmetro é excludente)\n",
        "X = df.iloc[:, 0:14].values"
      ],
      "metadata": {
        "id": "BTi4Ml0ffrNV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "r65JXWoI_S5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleção do target (Dados de saída)\n",
        "# Com o método .iloc selecionamos (por índice) todas as linhas, apenas a coluna 14 (income)\n",
        "y = df.iloc[:, 14].values"
      ],
      "metadata": {
        "id": "LhZwmixLfvQu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Em Machine Learning, o \"Label Encoding\" é o processo de conversão\n",
        "# de variáveis categóricas em variáveis numéricas (inteiros).\n",
        "\n",
        "# Em nosso dataframe, as colunas com variáveis categóricas (e seus índices) são:\n",
        "# workclass (1), education (3), marital (5), occupation (6), relationship (7), race (8), sex (9) e country (13)\n",
        "\n",
        "# Criaremos variáveis com o nome das colunas e aplicaremos a transformação para cada uma deles com o LabelEncoder():\n",
        "le_workclass = LabelEncoder()\n",
        "le_education = LabelEncoder()\n",
        "le_marital = LabelEncoder()\n",
        "le_occupation = LabelEncoder()\n",
        "le_relationship = LabelEncoder()\n",
        "le_race = LabelEncoder()\n",
        "le_sex = LabelEncoder()\n",
        "le_country = LabelEncoder()"
      ],
      "metadata": {
        "id": "rjG5hM_Ef0r3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando o método .fit_transform aplicamos os novos valores transformados às colunas:\n",
        "X[:,1] = le_workclass.fit_transform(X[:,1])\n",
        "X[:,3] = le_education.fit_transform(X[:,3])\n",
        "X[:,5] = le_marital.fit_transform(X[:,5])\n",
        "X[:,6] = le_occupation.fit_transform(X[:,6])\n",
        "X[:,7] = le_relationship.fit_transform(X[:,7])\n",
        "X[:,8] = le_race.fit_transform(X[:,8])\n",
        "X[:,9] = le_sex.fit_transform(X[:,9])\n",
        "X[:,13] = le_country.fit_transform(X[:,13])"
      ],
      "metadata": {
        "id": "Ag9BYqh4f7T5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "fmptGzvIf_Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padronização\n",
        "# É o redimensionamento dos recursos para criar um “padrão” garantindo\n",
        "# que os novos dados tenham média zero e desvio padrão igual a 1\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Salvando os novos dados já padronizados:\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "jdc5VIv8gCW7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "1kL1W76dgH1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Com o método train_test_split separamos os dados em treino e teste:\n",
        "# X_treino e y_treino: dados para treinamento dos modelos (80% dos dados iniciais)\n",
        "# X_teste e y_teste: dados para teste e avaliação dos modelos (20% dos dados iniciais)\n",
        "\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.20)"
      ],
      "metadata": {
        "id": "GRYXDQPngKM_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_treino.shape, X_teste.shape"
      ],
      "metadata": {
        "id": "zujBwX-1gPnf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}